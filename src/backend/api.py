import logging
import pdb
import uuid
from typing import Optional
import datetime

from fastapi import Request, APIRouter, Depends
from pydantic import BaseModel
from sqlalchemy.orm import Session

from .chat_history_db import ChatSession, Message, get_db
from .model import MAX_TOKENS

# Set up logging
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.DEBUG)

router = APIRouter()

class ChatRequest(BaseModel):
    prompt: str
    system_message: str
    session_id: Optional[str] = None
    clear_history: bool = False
    

@router.get("/")
def read_root():
    return {"message": "Chat API is running. Use POST /chat endpoint."}

@router.post("/chat")
def chat(req: ChatRequest, request: Request,  db: Session = Depends(get_db)):
    """Handle chat requests by generating a response from the LLaMA model.
    Note that `request` is generated by FastAPI for internal representation for backend. (Not sent by the client)
    """
    llm = request.app.state.llm
    logger.debug(f"Using LLM of type: {type(llm)}")


    # Get or create session ID
    session_id = req.session_id
    if not session_id:
        session_id = str(uuid.uuid4())

    db_session = db.query(ChatSession).filter(ChatSession.session_id == session_id).first()
    if not db_session:
        db_session = ChatSession(session_id=session_id)
        db.add(db_session)
        db.commit()
        logger.info(f"Created session for ID: {session_id}")

    system_message = req.system_message
    logger.debug(f"Using system message: {system_message[:50]}...")

    # Clear history if requested
    if req.clear_history:
        db.query(Message).filter(Message.session_id == session_id).delete()
        db.commit()
        logger.info(f"Cleared history for session {session_id}")
        return {"response": "History has been cleared!", "session_id": session_id}
    
    # Get history for this session
    db_messages = db.query(Message).filter(
        Message.session_id == session_id
    ).order_by(Message.timestamp).all()


    # Build messages list
    # Format for Llama 3.2 is OpenAI chat format
    messages = [
        {"role": "system", "content": system_message},
    ]
    [messages.append({"role": msg.role, "content": msg.content}) for msg in db_messages]

    # Add the new user message
    # validate that the new message + system message is within the token limit
    # llm.tokenize expects UTF-8 encoded bytes
    sys_msg_tokens = llm.tokenize(system_message.encode('utf-8'))
    new_msg_tokens = llm.tokenize(req.prompt.encode('utf-8'))
    num_new_msg_tokens = len(new_msg_tokens)
    num_syn_token = len(sys_msg_tokens)
    num_syn_msg_token = num_syn_token + num_new_msg_tokens
    assert num_syn_msg_token < MAX_TOKENS,\
        f"Input exceeds maximum token limit of {MAX_TOKENS}. Current count: {num_syn_msg_token}"
    messages.append({"role": "user", "content": req.prompt})
    logger.debug(f"Sending {len(messages)} messages to LLM")
    
    #NOTE: change max_tokens and stop parameters depending on your use-case
    # Output 
    output = llm.create_chat_completion(
        messages=messages, max_tokens=1000, temperature=1, repeat_penalty=1.2
        )
    logger.debug(f"Finish reason: {output['choices'][0]['finish_reason']}")
    response_text = output["choices"][0]["message"]["content"].strip()
    num_response_tokens = output["usage"]["completion_tokens"]
    num_total_tokens = output["usage"]["total_tokens"]

    # if total_tokens exceed the 80% of maximum_tokens_limit, we remove the oldest messages from the history
    # until the total tokens reach the 80% of maximum_tokens_limit
    max_tokens_limit = (MAX_TOKENS * 0.8) - num_syn_token
    if num_total_tokens > max_tokens_limit:
        logger.warning(f"Total tokens {num_total_tokens} exceed 80% of max limit {max_tokens_limit}. Trimming history.")
        # Calculate how many tokens we need to remove
        num_current = sum(msg.num_tokens for msg in db_messages)
        # Remove oldest messages until we reach the limit
        while (num_current > max_tokens_limit) and len(db_messages) > 0:
            oldest_msg = db_messages.pop(0)
            db.delete(oldest_msg)
            num_current -= oldest_msg.num_tokens
        db.commit()
    
    # Save the conversation to the database
    #TODO: Need Fix about num_tokens here
    db.add(Message(session_id=session_id, role="user", content=req.prompt, num_tokens=num_new_msg_tokens))
    db.add(Message(session_id=session_id, role="assistant", content=response_text, num_tokens=num_response_tokens))
    # Update session's last activity
    db_session.last_activity = datetime.datetime.now(datetime.timezone.utc)
    db.commit()
    
    return {"response": response_text, "session_id": session_id}

@router.get("/sessions")
def list_sessions(db: Session = Depends(get_db)):
    """List all available chat sessions."""
    sessions = db.query(ChatSession).all()
    result = []
    
    for session in sessions:
        message_count = db.query(Message).filter(Message.session_id == session.session_id).count()
        result.append({
            "session_id": session.session_id,
            "created_at": session.created_at.isoformat(),
            "last_activity": session.last_activity.isoformat(),
            "message_count": message_count
        })
    
    return {"sessions": result}

@router.get("/sessions/{session_id}")
def get_session(session_id: str, db: Session = Depends(get_db)):
    """Get a specific chat session's messages."""
    messages = db.query(Message).filter(
        Message.session_id == session_id
    ).order_by(Message.timestamp).all()
    
    return {
        "session_id": session_id,
        "messages": [{"role": msg.role, "content": msg.content} for msg in messages]
    }

@router.delete("/sessions/{session_id}")
def delete_session(session_id: str, db: Session = Depends(get_db)):
    """Delete a chat session."""
    session = db.query(ChatSession).filter(ChatSession.session_id == session_id).first()
    if session:
        db.delete(session)
        db.commit()
        return {"status": "success", "message": f"Session {session_id} deleted"}
    return {"status": "error", "message": "Session not found"}